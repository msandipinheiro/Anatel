{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANATEL TF-IDF Recomendação Baseada em Conteúdo\n",
    "\n",
    "Este código utiliza o TF-IDF (Term Frequency Inverse Document Frequency) para realizar a recomendação de resoluções da Anatel a partir de uma determinada resolução.\n",
    "\n",
    "O algoritmo retorna as \"top k\" resoluções similares as demais resoluções do arquivo CSV que contém as resoluções."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set o path do ambiente para encontrar o Recommenders\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "# Import functions\n",
    "from reco_utils.recommender.tfidf.tfidf_utils import TfidfRecommender\n",
    "\n",
    "# Import Pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Print version\n",
    "print(\"System version: {}\".format(sys.version))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Carrega o dataset no dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declara a váriavel filename com o nome do arquivo que contém as resoluções\n",
    "filename = 'resolucoes_text_2.csv'\n",
    "\n",
    "# Lê o arquivo, o qual está separado por '\\\\'\n",
    "df = pd.read_csv(filename, sep='\\\\')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifica o tamanho do arquivo e excluí as colunas nulas 'nan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview metadata for public domain articles\n",
    "print('tamanho: ' + str(len(df)))\n",
    "df.drop('Unnamed: 1', inplace=True, axis=1)\n",
    "df.drop('Unnamed: 3', inplace=True, axis=1)\n",
    "df.drop('Unnamed: 4', inplace=True, axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Instancia o recommender\n",
    "Todas as funcções para a preparação dos dados e das recomendações estão na classe **TfidfRecommender** a qual foi importada. Antes de executar estas funções, é necessário criar um objeto desta classe. \n",
    "\n",
    "Selecione um dos seguintes métodos de tokenização (tokenization) para utilizar no modelo:\n",
    "\n",
    "| tokenization_method | Descrição                                                                                                                      |\n",
    "|:--------------------|:---------------------------------------------------------------------------------------------------------------------------------|\n",
    "| 'none'              | Nenhuma tokenização é aplicada. Cada palavra é considerada um token.                                                                     |\n",
    "| 'nltk'              | Simple stemming é aplicado usando NLTK.                                                                                           |\n",
    "| 'bert'              | HuggingFace BERT word tokenization ('bert-base-cased') é aplicado.                                                               |\n",
    "| 'scibert'           | SciBERT word tokenization ('allenai/scibert_scivocab_cased') é aplicado.<br> Este método é indicado para artigos científicos. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria o objeto recommender\n",
    "recommender = TfidfRecommender(id_col='id_resolucao', tokenization_method='scibert')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Prepara o texto para uso no TF-IDF recommender\n",
    "\n",
    "Verificando o texto de uma resolução como exemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the first 1000 characters of the full scientific text from one example\n",
    "print(df['Texto'][0][:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos textos das resoluções há alguns caracteres especiais (tais como • ▲ ■ ≥ °) e pontuação que dever ser removidas antes de incluir o text no dataframe. Letras maiúsculas são mantidas para o [BERT-based tokenization methods](https://huggingface.co/transformers/model_doc/bert.html), mas é removida para simple ou no tokenization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Designa a coluna na qual será realizada a limpeza\n",
    "cols_to_clean = ['Texto']\n",
    "clean_col = 'cleaned_text'\n",
    "df_clean = recommender.clean_dataframe(df, cols_to_clean, clean_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faz um preview do dataframe com o texto limpo\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faz um preview dos primeiros 1000 caracteres do campo cleaned_text\n",
    "print(df_clean[clean_col][0][:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realiza a tokenização do texto limpo (cleaned_text)para utilizar no modelo TF-IDF. Os tokens são armazenados no objeto TfidfRecommender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realiza a tokenização do texto com o método definido na classe instanciada\n",
    "tf, vectors_tokenized = recommender.tokenize_text(df_clean, text_col=clean_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Recomenda as resoluções utilizando o TF-IDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Ajusta a vetorização do TF-IDF\n",
    "recommender.fit(tf, vectors_tokenized)\n",
    "\n",
    "# Recebe as recomendações\n",
    "top_k_recommendations = recommender.recommend_top_k_items(df_clean, k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our recommendation table, each row represents a single recommendation.\n",
    "\n",
    "- **cord_uid** corresponds to the article that is being used to make recommendations from.\n",
    "- **rec_rank** contains the recommdation's rank (e.g., rank of 1 means top recommendation).\n",
    "- **rec_score** is the cosine similarity score between the query article and the recommended article.\n",
    "- **rec_cord_uid** corresponds to the recommended article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiza as recomendações\n",
    "top_k_recommendations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (reco)",
   "language": "python",
   "name": "reco_base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
